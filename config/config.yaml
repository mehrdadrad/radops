logging:
  level: info

agent:
  supervisor:
    llm_profile: openai-main
  auditor:
    enabled: true
    llm_profile: openai-main
  guardrail:
    enabled: false
    llm_profile: openai-main
  profiles:
    network_agent:
      description: "Specialist for network connectivity, latency, DNS, BGP, ASN/PeeringDB lookups, and IP routing issues."
      llm_profile: "openai-main"
      system_prompt_file: "../config/prompts/network_agent_prompt.txt"
      allow_tools:
        - system__.*
        - kb.*
        - network.*
    cloud_agent:
      description: "Specialist for AWS cloud infrastructure, EC2, VPC, IAM, and observability."
      llm_profile: "openai-main"
      system_prompt_file: "../config/prompts/cloud_agent_prompt.txt"
      allow_tools:
        - system__.*
        - aws.*
    support_agent:
      description: "Specialist for operational support tasks: managing Jira tickets, PagerDuty incidents, GitHub issues, and searching the Knowledge Base."
      llm_profile: "openai-main"
      system_prompt_file: "../config/prompts/support_agent_prompt.txt"
      allow_tools:
        - system__.*
        - kb.*
        - jira.*
        - pagerduty.*
        - notion.*
        - github.*
        - mcp_echo_tool
 
vector_store:
  profiles:
    - name: vs01 
      provider: weaviate
      embedding_profile: "openai-embedding-small"
      sync_locations: 
        - name: router config
          type: fs
          path: ../data
          collection: router_config_kb
          sync_interval: 300
          prompt_file: "../config/prompts/kb_device_prompt.txt"
          metadata:
            delimiter: _
            structure: 
              - name: "device"
                description: "The specific device name (e.g., 'router1') to filter the search. Use this if the user specifies a device."
              - name: "location"
                description: "The specific location name(e.g., 'lax01') to filter the search. Use this if the user specifies a location."
        - name: local docs
          type: gdrive
          path: 1VAucwU6CJkXSIESRkMUNBGBIctKLupiC
          collection: team_kb
          sync_interval: 300
          prompt_file: "../config/prompts/kb_team_prompt.txt"
          metadata:
            delimiter: _
            structure: []
  providers:
    weaviate:
      http_host: localhost
      http_port: 8088
      http_secure: false
      grpc_host: localhost
      grpc_port: 50051
      grpc_secure: false
    chroma:
      persist_dir: ./chroma_db_data
    pinecone:
      index_name: radops
      api_key: vault:system#pinecone_key
    qdrant:
      url: https://93c5b57d-d6ef-46d0-aca1-6d33cd4cb9f9.us-east4-0.gcp.cloud.qdrant.io
      port: 6333
      api_key: vault:system#qdrant_key
    milvus:
      uri: https://in03-3ada559110f49ce.serverless.gcp-us-west1.cloud.zilliz.com
      user: db_3ada559110f49ce
      password: vault:system#milvus_password
      token: vault:system#milvus_token

memory:
  redis:
    endpoint: redis://localhost:6355
    ttl:
      time_minutes: 5
      refresh_on_read: true
  summarization:
    keep_message: 20 
    llm_profile: "openai-summary"

mem0:
  llm_profile: "openai-summary"
  embedding_profile: "openai-embedding-small"
  limit: 3
  excluded_tools:
    - router_configuration_retriever
    - set_user_secrets
  vector_store:
    provider: "weaviate"
    config:
      collection_name: Mem0_Memory
      cluster_url: http://127.0.0.1:8088
    # provider: "chroma"
    # config:
    #   path: ./mem0_db_data

llm:
  default_profile: "openai-main" # Set a default profile for general use
  profiles:
    openai-main:
      provider: "openai"
      #model: "gpt-3.5-turbo-16k"
      model: "gpt-4o-mini"
      temperature: 0.0
      max_tokens: 3000
      api_key: vault:system#openai_key
    openai-summary:
      provider: "openai"
      model: "gpt-3.5-turbo-16k" 
      temperature: 0.3 
      max_tokens: 1500 
      api_key: vault:system#openai_key
    openai-guardrail:
      provider: "openai"
      model: "gpt-4o-mini" 
      temperature: 0 
      api_key: vault:system#openai_key
    openai-embedding-small:
      provider: "openai"
      model: "text-embedding-3-small"
      api_key: vault:system#openai_key
      dimensions: 1536
    ollama-main:
      provider: "ollama"
      model: "gpt-oss:20b"
      base_url: "http://localhost:11434"
    deepseek-main:
      provider: "deepseek"
      model: "deepseek-chat"
      temperature: 0.0
      max_tokens: 1000
      api_key: vault:system#deepseek_key
      base_url: "https://api.deepseek.com/v1"
    anthropic-main:
      provider: "anthropic"
      model: "claude-sonnet-4-20250514"
      temperature: 0.0
      max_tokens: 1000
      api_key: vault:system#anthropic_key
 

vault:
  url: http://localhost:8200
  token: my-dev-token

opentelemetry:
  prometheus:
    address: 127.0.0.1
    port: 9464
